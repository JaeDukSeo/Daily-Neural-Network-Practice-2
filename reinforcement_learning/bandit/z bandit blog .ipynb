{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:29:27.640901Z",
     "start_time": "2019-01-13T01:29:26.638907Z"
    }
   },
   "source": [
    "### Compare Listing \n",
    "<ol>\n",
    "<li>a: vector uniform</li>\n",
    "<li>b: greedy</li>\n",
    "<li>c: e - greedy</li>\n",
    "<li>d: decay e - greedy</li>\n",
    "<li>e: Linear Reward Inaction (Pursuit Methods)</li>\n",
    "<li>f: Linear Reward Penalty (Pursuit Methods)</li>\n",
    "<li>g: UBC 1</li>\n",
    "<li>h: UCB 1-Tuned</li>\n",
    "<li>i: Thompson Sampling (beta)</li>\n",
    "<li>j: Thompson Sampling (uniform)</li>\n",
    "<li>k: Neural Network</li>\n",
    "<li>l: softmax </li>\n",
    "<li>m: Gradient Bandits</li>\n",
    "<li>n: Non Stationary</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T05:31:39.383974Z",
     "start_time": "2019-01-14T05:31:26.552073Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy,time,sys\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import beta\n",
    "np.random.seed(5678)\n",
    "np.set_printoptions(3)\n",
    "tf.set_random_seed(678)\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T05:31:39.403920Z",
     "start_time": "2019-01-14T05:31:39.394945Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Best Choice:  11 0.7364685816073836\n"
     ]
    }
   ],
   "source": [
    "# setting the ground truth\n",
    "num_bandit = 12\n",
    "num_ep  = 20\n",
    "num_iter= 1000\n",
    "gt_prob = np.random.uniform(0,1,num_bandit)\n",
    "optimal_choice = np.argmax(gt_prob)\n",
    "print(gt_prob)\n",
    "print('Best Choice: ',optimal_choice,gt_prob[optimal_choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T05:32:08.136712Z",
     "start_time": "2019-01-14T05:32:08.110745Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.481 0.057 0.354 0.528 0.599 0.423 0.17  0.275 0.084 0.182 0.084 0.758]\n"
     ]
    }
   ],
   "source": [
    "# a vectorized\n",
    "a_expect = np.zeros((num_ep,num_bandit))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_expect = np.zeros(num_bandit)\n",
    "    temp_choice = np.zeros(num_bandit)\n",
    "                    \n",
    "    for iter in range(num_iter//10):\n",
    "        temp_choice    = temp_choice + 1\n",
    "        current_reward = np.random.uniform(0,1,num_bandit) < gt_prob\n",
    "        temp_expect    = temp_expect + current_reward\n",
    "\n",
    "    a_expect[eps,:] = temp_expect/temp_choice\n",
    "                    \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(a_expect.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:25:36.813205Z",
     "start_time": "2019-01-14T06:25:36.653641Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.484 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "# b greedy\n",
    "b_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "b_estimation   = np.zeros((num_ep,num_bandit))\n",
    "b_reward       = np.zeros((num_ep,num_iter))\n",
    "b_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "b_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_estimation)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    b_pull_count[eps,:]   = temp_pull_count\n",
    "    b_estimation[eps,:]   = temp_estimation\n",
    "    b_reward[eps,:]       = temp_reward\n",
    "    b_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    b_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(b_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:25:37.435275Z",
     "start_time": "2019-01-14T06:25:37.184025Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.461 0.049 0.316 0.513 0.577 0.401 0.164 0.244 0.071 0.184 0.074 0.734]\n"
     ]
    }
   ],
   "source": [
    "# c e greedy \n",
    "c_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "c_estimation   = np.zeros((num_ep,num_bandit))\n",
    "c_reward       = np.zeros((num_ep,num_iter))\n",
    "c_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "c_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    epsilon = np.random.uniform(0,1)\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "  \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_expect) if epsilon < np.random.uniform(0,1) else np.random.choice(np.arange(num_bandit))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    c_pull_count[eps,:]   = temp_pull_count\n",
    "    c_estimation[eps,:]   = temp_estimation\n",
    "    c_reward[eps,:]       = temp_reward\n",
    "    c_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    c_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(c_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:27:32.900065Z",
     "start_time": "2019-01-14T06:27:32.701597Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.436 0.018 0.359 0.438 0.487 0.39  0.155 0.221 0.034 0.118 0.076 0.734]\n"
     ]
    }
   ],
   "source": [
    "# d decy e greedy \n",
    "d_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "d_estimation   = np.zeros((num_ep,num_bandit))\n",
    "d_reward       = np.zeros((num_ep,num_iter))\n",
    "d_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "d_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    epsilon = 1.0\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_expect) if epsilon < np.random.uniform(0,1) else np.random.choice(np.arange(num_bandit))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "        # decay the eps\n",
    "        epsilon = 0.99 * epsilon\n",
    "        \n",
    "    d_pull_count[eps,:]   = temp_pull_count\n",
    "    d_estimation[eps,:]   = temp_estimation\n",
    "    d_reward[eps,:]       = temp_reward\n",
    "    d_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    d_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(d_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:33:35.557535Z",
     "start_time": "2019-01-14T06:33:34.744770Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.   0.   0.   0.1  0.2  0.05 0.   0.   0.   0.   0.   0.65]\n",
      "Expected Normalized\n",
      "[0.    0.    0.    0.401 0.801 0.2   0.    0.    0.    0.    0.    2.604]\n"
     ]
    }
   ],
   "source": [
    "# e Linear Reward Inaction\n",
    "e_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "e_estimation   = np.zeros((num_ep,num_bandit))\n",
    "e_reward       = np.zeros((num_ep,num_iter))\n",
    "e_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "e_regret_total = np.zeros((num_ep,num_iter))\n",
    "      \n",
    "for eps in range(num_ep):\n",
    "    learning_rate = 0.1\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit) + 1.0/num_bandit\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.random.choice(num_bandit, p=temp_estimation)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        \n",
    "        mask = np.zeros(num_bandit)\n",
    "        mask[current_choice] = 1.0\n",
    "        \n",
    "        if current_reward == 1.0:\n",
    "            temp_estimation = (mask) * (temp_estimation + learning_rate * (1-temp_estimation)) + (1-mask) * ( (1-learning_rate) * temp_estimation)\n",
    "            \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    e_pull_count[eps,:]   = temp_pull_count\n",
    "    e_estimation[eps,:]   = temp_estimation\n",
    "    e_reward[eps,:]       = temp_reward\n",
    "    e_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    e_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(np.around(e_estimation.mean(0),3))\n",
    "print('Expected Normalized')\n",
    "print(np.around(e_estimation.mean(0),3)* gt_prob.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:35:57.107981Z",
     "start_time": "2019-01-14T06:35:56.257980Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.057 0.007 0.031 0.08  0.15  0.037 0.008 0.017 0.007 0.009 0.006 0.591]\n",
      "Expected Normalized\n",
      "[0.229 0.028 0.124 0.319 0.6   0.147 0.034 0.069 0.026 0.036 0.026 2.37 ]\n"
     ]
    }
   ],
   "source": [
    "# f Linear Reward Penalty\n",
    "f_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "f_estimation   = np.zeros((num_ep,num_bandit))\n",
    "f_reward       = np.zeros((num_ep,num_iter))\n",
    "f_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "f_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    alpha = 0.01\n",
    "    beta  = 0.001\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit) + 1.0/num_bandit\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    \n",
    "    for iter in range(num_iter):\n",
    "\n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.random.choice(num_bandit, p=temp_estimation)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "\n",
    "        mask = np.zeros(num_bandit)\n",
    "        mask[current_choice] = 1.0\n",
    "        \n",
    "        if current_reward == 1.0:\n",
    "            temp_estimation = (mask) * (temp_estimation + alpha * (1-temp_estimation)) + (1-mask) * ( (1-alpha) * temp_estimation)\n",
    "        else: \n",
    "            temp_estimation = (mask) * ((1-beta) * temp_estimation) + (1-mask) * ( beta/(num_bandit-1) + (1-beta) * temp_estimation )\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    f_pull_count[eps,:]   = temp_pull_count\n",
    "    f_estimation[eps,:]   = temp_estimation\n",
    "    f_reward[eps,:]       = temp_reward\n",
    "    f_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    f_regret_total[eps,:] = temp_regret\n",
    "    \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(f_estimation.mean(0))\n",
    "print('Expected Normalized')\n",
    "print(f_estimation.mean(0) * gt_prob.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:37:39.496894Z",
     "start_time": "2019-01-14T06:37:39.202158Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.429 0.033 0.277 0.414 0.556 0.404 0.115 0.17  0.037 0.164 0.077 0.732]\n"
     ]
    }
   ],
   "source": [
    "# g UBC\n",
    "g_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "g_estimation   = np.zeros((num_ep,num_bandit))\n",
    "g_reward       = np.zeros((num_ep,num_iter))\n",
    "g_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "g_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_estimation + np.sqrt(0.5*np.log(iter+1)/(temp_pull_count+1)))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    g_pull_count[eps,:]   = temp_pull_count\n",
    "    g_estimation[eps,:]   = temp_estimation\n",
    "    g_reward[eps,:]       = temp_reward\n",
    "    g_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    g_regret_total[eps,:] = temp_regret\n",
    "  \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(g_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:21:50.280119Z",
     "start_time": "2019-01-14T06:21:49.983217Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.46  0.047 0.34  0.514 0.568 0.428 0.142 0.244 0.058 0.145 0.066 0.732]\n"
     ]
    }
   ],
   "source": [
    "# h UBC Tuned\n",
    "h_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "h_estimation   = np.zeros((num_ep,num_bandit))\n",
    "h_reward       = np.zeros((num_ep,num_iter))\n",
    "h_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit) \n",
    "    temp_estimation   = np.zeros(num_bandit) \n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        current_min_value = 1\n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_estimation + np.sqrt(np.log(iter+1)/(temp_pull_count+1)*current_min_value))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = temp_reward[iter] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        \n",
    "    h_pull_count[eps,:]   = temp_pull_count\n",
    "    h_estimation[eps,:]   = temp_estimation\n",
    "    h_reward[eps,:]       = temp_reward\n",
    "    h_optimal_pull[eps,:] = temp_optimal_pull\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(h_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:42:23.483603Z",
     "start_time": "2019-01-14T06:39:25.279995Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.462 0.2   0.312 0.394 0.545 0.35  0.203 0.33  0.14  0.247 0.253 0.735]\n"
     ]
    }
   ],
   "source": [
    "# i Thompson Sampling (beta) (slow)\n",
    "i_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "i_estimation   = np.zeros((num_ep,num_bandit))\n",
    "i_reward       = np.zeros((num_ep,num_iter))\n",
    "i_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "i_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        theta_samples = [stats.beta(a=1+w,b=1+t-w).rvs(size=1) for t, w in zip(temp_pull_count, temp_estimation)]\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(theta_samples)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + current_reward\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    i_pull_count[eps,:]   = temp_pull_count\n",
    "    i_estimation[eps,:]   = theta_samples\n",
    "    i_reward[eps,:]       = temp_reward\n",
    "    i_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    i_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(i_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:45:12.311374Z",
     "start_time": "2019-01-14T06:42:23.624280Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.736 0.586 0.753 0.754 0.722 0.687 0.487 0.602 0.474 0.703 0.435 0.879]\n"
     ]
    }
   ],
   "source": [
    "# j Thompson Sampling (uniform) (slow)\n",
    "j_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "j_estimation   = np.zeros((num_ep,num_bandit))\n",
    "j_reward       = np.zeros((num_ep,num_iter))\n",
    "j_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "j_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        theta_samples = [stats.uniform(w/(t+0.000000001),1-w/(t+0.000000001)).rvs(size=1) for t, w in zip(temp_pull_count, temp_estimation)]\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(theta_samples)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + current_reward\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    j_pull_count[eps,:]   = temp_pull_count\n",
    "    j_estimation[eps,:]   = theta_samples\n",
    "    j_reward[eps,:]       = temp_reward\n",
    "    j_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    j_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(j_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:48:36.959857Z",
     "start_time": "2019-01-14T06:48:35.873742Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.355 0.109 0.294 0.417 0.466 0.366 0.157 0.24  0.109 0.251 0.16  0.612]\n"
     ]
    }
   ],
   "source": [
    "# k neural network (with adam)\n",
    "k_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "k_estimation   = np.zeros((num_ep,num_bandit))\n",
    "k_reward       = np.zeros((num_ep,num_iter))\n",
    "k_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "k_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "def sigmoid(x): return 1/(1+np.exp(-x))\n",
    "def d_sigmoid(x): return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    \n",
    "    weights = np.random.randn(num_bandit,1)\n",
    "    moment  = np.zeros_like(weights); \n",
    "    velocity = np.zeros_like(weights);\n",
    "    epsilon  = 0.1\n",
    "\n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        if np.random.uniform(0,1)>epsilon:\n",
    "            current_choice = np.argmax(weights)\n",
    "            current_input  = np.zeros((1,num_bandit))\n",
    "            current_input[0,current_choice] = 1\n",
    "        else:\n",
    "            current_choice = np.random.choice(np.arange(num_bandit))\n",
    "            current_input  = np.zeros((1,num_bandit))\n",
    "            current_input[0,current_choice] = 1\n",
    "\n",
    "        layer1 = current_input @ weights\n",
    "        layer1a= sigmoid(layer1)\n",
    "\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + current_reward\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        \n",
    "        # KL Divergence https://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/\n",
    "        grad3 = np.log(layer1a+0.0000001) - np.log(temp_estimation[current_choice]/(temp_pull_count[current_choice])+0.0000001)\n",
    "        grad2 = d_sigmoid(layer1)\n",
    "        grad1 = current_input\n",
    "        grad  = grad1.T @ (grad3 * grad2)\n",
    "        \n",
    "        moment   = 0.9*moment + (1-0.9) * grad\n",
    "        velocity = 0.999*velocity + (1-0.999) * grad**2\n",
    "        moment_hat   = moment/(1-0.9)\n",
    "        velocity_hat = velocity/(1-0.999)\n",
    "        weights  = weights - 0.08 * (moment_hat/(np.sqrt(velocity_hat)+1e-8))\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "        # Decay the learning rate\n",
    "        epsilon = epsilon * 0.999\n",
    "        \n",
    "    k_pull_count[eps,:]   = temp_pull_count\n",
    "    k_estimation[eps,:]   = np.squeeze(sigmoid(weights))\n",
    "    k_reward[eps,:]       = temp_reward\n",
    "    k_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    k_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(k_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:48:18.494764Z",
     "start_time": "2019-01-14T06:48:17.949191Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.484 0.06  0.367 0.515 0.572 0.412 0.183 0.27  0.056 0.183 0.093 0.744]\n"
     ]
    }
   ],
   "source": [
    "# l softmax\n",
    "l_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "l_estimation   = np.zeros((num_ep,num_bandit))\n",
    "l_reward       = np.zeros((num_ep,num_iter))\n",
    "l_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "l_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "    tempture = 300\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        pi  = np.exp(temp_estimation/tempture) / np.sum(np.exp(temp_estimation/tempture))\n",
    "        cdf = np.cumsum(pi)\n",
    "        current_choice = np.where(np.random.uniform(0,1) < cdf)[0][0]\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "        # decay the temp\n",
    "        tempture = tempture * 0.999999\n",
    "        \n",
    "    l_pull_count[eps,:]   = temp_pull_count\n",
    "    l_estimation[eps,:]   = temp_estimation\n",
    "    l_reward[eps,:]       = temp_reward\n",
    "    l_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    l_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(l_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:10:36.712012Z",
     "start_time": "2019-01-14T06:10:36.708024Z"
    }
   },
   "outputs": [],
   "source": [
    "# m gradient base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n non stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:50:08.236890Z",
     "start_time": "2019-01-14T06:50:08.008490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(b_regret_total.mean(0),label='greedy')\n",
    "plt.plot(c_regret_total.mean(0),label='e greedy')\n",
    "plt.plot(d_regret_total.mean(0),label='decay e greedy')\n",
    "plt.plot(e_regret_total.mean(0),label='pursit')\n",
    "plt.plot(f_regret_total.mean(0),label='pursit')\n",
    "plt.plot(g_regret_total.mean(0),label='UBC')\n",
    "# plt.plot(h_regret_total.mean(0),label='UBC')\n",
    "plt.plot(i_regret_total.mean(0),label='beta')\n",
    "plt.plot(j_regret_total.mean(0),label='uniform')\n",
    "plt.plot(k_regret_total.mean(0),label='NN')\n",
    "plt.plot(l_regret_total.mean(0),label='softmax')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l_reward.mean(0),label='greedy')\n",
    "plt.plot(l_reward.mean(0),label='e greedy')\n",
    "plt.plot(l_reward.mean(0),label='decay e greedy')\n",
    "plt.plot(l_reward.mean(0),label='pursit')\n",
    "plt.plot(l_reward.mean(0),label='pursit')\n",
    "plt.plot(l_reward.mean(0),label='UBC')\n",
    "# plt.plot(l_reward.mean(0),label='UBC')\n",
    "plt.plot(l_reward.mean(0),label='beta')\n",
    "plt.plot(l_reward.mean(0),label='uniform')\n",
    "plt.plot(l_reward.mean(0),label='NN')\n",
    "plt.plot(l_reward.mean(0),label='softmax')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:45:15.096816Z",
     "start_time": "2019-01-14T06:45:15.075872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"04a518b9-050d-4c31-b7df-e1a780142b47\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"04a518b9-050d-4c31-b7df-e1a780142b47\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:50:52.230664Z",
     "start_time": "2019-01-13T01:50:51.987646Z"
    }
   },
   "source": [
    "# Reference \n",
    "1. numpy.set_printoptions  NumPy v1.14 Manual. (2019). Docs.scipy.org. Retrieved 13 January 2019, from https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.set_printoptions.html\n",
    "2. [ Archived Post ] Random Note about Multi-Arm Bandit Problem 2. (2019). Medium. Retrieved 13 January 2019, from https://medium.com/@SeoJaeDuk/archived-post-random-note-about-multi-arm-bandit-problem-2-5c522d1dfbdc\n",
    "3. Vieira, T. (2014). KL-divergence as an objective function  Graduate Descent. Timvieira.github.io. Retrieved 13 January 2019, from https://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/\n",
    "4. Some Reinforcement Learning: The Greedy and Explore-Exploit Algorithms for the Multi-Armed Bandit Framework in Python. (2019). Datasciencecentral.com. Retrieved 13 January 2019, from https://www.datasciencecentral.com/profiles/blogs/some-reinforcement-learning-the-greedy-and-explore-exploit\n",
    "5. (2019). Cs.mcgill.ca. Retrieved 13 January 2019, from https://www.cs.mcgill.ca/~vkules/bandits.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
